"""
Script 5: An√°lisis Discriminante
Implementa LDA para evaluar discriminaci√≥n entre grupos.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.impute import SimpleImputer
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from pathlib import Path

# Configuraci√≥n de estilo
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

def cargar_y_preparar_datos():
    """Carga y prepara los datos"""
    print("üìÇ Cargando datos...")
    
    df_valores = pd.read_excel('../BASE_NOMBRES_Y_VALORES.xlsx')
    df_etiquetas = pd.read_excel('../BASE_ETIQUETAS.xlsx')
    
    print(f"‚úì Valores: {df_valores.shape}")
    print(f"‚úì Etiquetas: {df_etiquetas.shape}")
    
    return df_valores, df_etiquetas

def identificar_variable_categorica(df_valores, df_etiquetas):
    """
    Identifica una variable categ√≥rica adecuada para el an√°lisis discriminante
    """
    print("\nüîç Identificando variables categ√≥ricas adecuadas...")
    
    candidatos = []
    
    for col in df_valores.columns:
        if col in df_etiquetas.columns:
            # Contar valores √∫nicos
            n_unicos = df_valores[col].nunique()
            
            # Debe tener entre 2 y 5 categor√≠as (ideal para LDA)
            if 2 <= n_unicos <= 5:
                # Verificar que no tenga muchos valores faltantes
                pct_faltantes = df_valores[col].isnull().sum() / len(df_valores) * 100
                
                if pct_faltantes < 50:  # Menos de 50% faltantes
                    candidatos.append({
                        'variable': col,
                        'n_categorias': n_unicos,
                        'pct_faltantes': pct_faltantes,
                        'valores': df_valores[col].value_counts().to_dict()
                    })
    
    if not candidatos:
        print("‚ö†Ô∏è  No se encontraron variables categ√≥ricas adecuadas")
        print("   Creando variable artificial basada en cuartiles de la primera variable num√©rica...")
        
        # Crear variable categ√≥rica artificial
        primera_numerica = df_valores.select_dtypes(include=[np.number]).columns[0]
        df_valores['Grupo_Artificial'] = pd.qcut(df_valores[primera_numerica].dropna(), 
                                                   q=3, labels=['Bajo', 'Medio', 'Alto'])
        return 'Grupo_Artificial', df_valores
    
    # Ordenar por n√∫mero de categor√≠as (preferir 2-3 categor√≠as)
    candidatos.sort(key=lambda x: abs(x['n_categorias'] - 2.5))
    
    print(f"\n‚úì Se encontraron {len(candidatos)} variables categ√≥ricas adecuadas:")
    for i, cand in enumerate(candidatos[:3]):
        print(f"   {i+1}. {cand['variable']}: {cand['n_categorias']} categor√≠as")
        print(f"      Distribuci√≥n: {cand['valores']}")
    
    # Seleccionar la mejor
    mejor = candidatos[0]['variable']
    print(f"\n‚úÖ Variable seleccionada: {mejor}")
    
    return mejor, df_valores

def preparar_datos_discriminante(df_valores, variable_objetivo):
    """Prepara datos para an√°lisis discriminante"""
    print(f"\nüìä Preparando datos para an√°lisis discriminante...")
    
    # Separar X (predictores) e y (variable objetivo)
    y = df_valores[variable_objetivo].copy()
    X = df_valores.drop(variable_objetivo, axis=1)
    
    # Seleccionar solo columnas num√©ricas
    X_numeric = X.select_dtypes(include=[np.number])
    
    # Eliminar filas con valores faltantes en y
    mask = y.notna()
    X_numeric = X_numeric[mask]
    y = y[mask]
    
    # Imputar valores faltantes en X
    imputer = SimpleImputer(strategy='mean')
    X_imputed = pd.DataFrame(
        imputer.fit_transform(X_numeric),
        columns=X_numeric.columns,
        index=X_numeric.index
    )
    
    # Codificar variable objetivo si es categ√≥rica
    if y.dtype == 'object' or y.dtype.name == 'category':
        le = LabelEncoder()
        y_encoded = le.fit_transform(y)
        clases = le.classes_
    else:
        y_encoded = y.values
        clases = sorted(y.unique())
    
    print(f"‚úì Predictores: {X_imputed.shape[1]} variables")
    print(f"‚úì Observaciones: {len(y_encoded)}")
    print(f"‚úì Clases: {len(np.unique(y_encoded))} - {clases}")
    
    # Distribuci√≥n de clases
    unique, counts = np.unique(y_encoded, return_counts=True)
    print(f"\n   Distribuci√≥n de clases:")
    for clase, count in zip(clases, counts):
        pct = count / len(y_encoded) * 100
        print(f"      ‚Ä¢ {clase}: {count} ({pct:.1f}%)")
    
    return X_imputed, y_encoded, clases

def realizar_analisis_discriminante(X, y, clases):
    """Realiza el an√°lisis discriminante lineal"""
    print(f"\nüî¨ Realizando An√°lisis Discriminante Lineal (LDA)...")
    
    # Dividir en entrenamiento y prueba
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=42, stratify=y
    )
    
    print(f"‚úì Datos de entrenamiento: {len(X_train)}")
    print(f"‚úì Datos de prueba: {len(X_test)}")
    
    # Estandarizar
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # Crear y entrenar modelo LDA
    lda = LinearDiscriminantAnalysis()
    lda.fit(X_train_scaled, y_train)
    
    # Predecir
    y_pred_train = lda.predict(X_train_scaled)
    y_pred_test = lda.predict(X_test_scaled)
    
    # Calcular exactitud
    acc_train = accuracy_score(y_train, y_pred_train)
    acc_test = accuracy_score(y_test, y_pred_test)
    
    print(f"\n‚úì Modelo LDA entrenado")
    print(f"   Exactitud en entrenamiento: {acc_train*100:.2f}%")
    print(f"   Exactitud en prueba: {acc_test*100:.2f}%")
    
    return lda, X_test_scaled, y_test, y_pred_test, clases, acc_test

def crear_matriz_confusion(y_true, y_pred, clases, output_dir='../graficos'):
    """Crea y visualiza la matriz de confusi√≥n"""
    
    Path(output_dir).mkdir(exist_ok=True)
    
    cm = confusion_matrix(y_true, y_pred)
    
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=clases, yticklabels=clases,
                cbar_kws={'label': 'Frecuencia'})
    plt.xlabel('Predicci√≥n', fontsize=12)
    plt.ylabel('Valor Real', fontsize=12)
    plt.title('Matriz de Confusi√≥n - An√°lisis Discriminante', fontsize=14, fontweight='bold')
    plt.tight_layout()
    
    path = Path(output_dir) / 'matriz_confusion_lda.png'
    plt.savefig(path, dpi=300, bbox_inches='tight')
    print(f"\nüìä Matriz de confusi√≥n guardada: {path}")
    plt.close()
    
    return cm

def visualizar_discriminantes(lda, X_test, y_test, clases, output_dir='../graficos'):
    """Visualiza las funciones discriminantes"""
    
    Path(output_dir).mkdir(exist_ok=True)
    
    # Transformar datos al espacio discriminante
    X_lda = lda.transform(X_test)
    
    # Si hay m√°s de 1 dimensi√≥n, graficar 2D
    if X_lda.shape[1] >= 2:
        plt.figure(figsize=(10, 7))
        
        for i, clase in enumerate(np.unique(y_test)):
            mask = y_test == clase
            plt.scatter(X_lda[mask, 0], X_lda[mask, 1], 
                       label=clases[i], alpha=0.6, s=50, edgecolors='black', linewidth=0.5)
        
        plt.xlabel('LD1 (Primera Funci√≥n Discriminante)', fontsize=12)
        plt.ylabel('LD2 (Segunda Funci√≥n Discriminante)', fontsize=12)
        plt.title('Visualizaci√≥n en Espacio Discriminante', fontsize=14, fontweight='bold')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        
        path = Path(output_dir) / 'espacio_discriminante.png'
        plt.savefig(path, dpi=300, bbox_inches='tight')
        print(f"üìä Visualizaci√≥n discriminante guardada: {path}")
        plt.close()
    
    # Gr√°fico 1D si solo hay una funci√≥n discriminante
    elif X_lda.shape[1] == 1:
        plt.figure(figsize=(10, 6))
        
        for i, clase in enumerate(np.unique(y_test)):
            mask = y_test == clase
            plt.hist(X_lda[mask, 0], alpha=0.6, label=clases[i], bins=20)
        
        plt.xlabel('LD1 (Funci√≥n Discriminante)', fontsize=12)
        plt.ylabel('Frecuencia', fontsize=12)
        plt.title('Distribuci√≥n en Espacio Discriminante', fontsize=14, fontweight='bold')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        
        path = Path(output_dir) / 'espacio_discriminante.png'
        plt.savefig(path, dpi=300, bbox_inches='tight')
        print(f"üìä Visualizaci√≥n discriminante guardada: {path}")
        plt.close()

def analizar_coeficientes(lda, nombres_variables, clases, output_dir='../resultados'):
    """Analiza los coeficientes discriminantes"""
    
    Path(output_dir).mkdir(exist_ok=True)
    
    # Obtener coeficientes
    coeficientes = lda.coef_
    
    # Crear DataFrame
    n_funciones = coeficientes.shape[0]
    
    df_coef = pd.DataFrame(
        coeficientes.T,
        columns=[f'LD{i+1}' for i in range(n_funciones)],
        index=nombres_variables
    )
    
    # A√±adir importancia (valor absoluto m√°ximo)
    df_coef['Importancia'] = df_coef.abs().max(axis=1)
    df_coef = df_coef.sort_values('Importancia', ascending=False)
    
    # Guardar
    path = Path(output_dir) / 'coeficientes_discriminantes.xlsx'
    df_coef.to_excel(path)
    print(f"üìä Coeficientes discriminantes guardados: {path}")
    
    return df_coef

def generar_reporte_discriminante(variable_obj, clases, accuracy, cm, df_coef, output_dir='../resultados'):
    """Genera reporte del an√°lisis discriminante"""
    
    Path(output_dir).mkdir(exist_ok=True)
    
    reporte = []
    reporte.append("=" * 80)
    reporte.append("üìä REPORTE DE AN√ÅLISIS DISCRIMINANTE LINEAL (LDA)")
    reporte.append("=" * 80)
    reporte.append("")
    
    # Variable objetivo
    reporte.append("1Ô∏è‚É£ VARIABLE CATEG√ìRICA SELECCIONADA")
    reporte.append("-" * 80)
    reporte.append(f"   Variable: {variable_obj}")
    reporte.append(f"   Clases: {', '.join(map(str, clases))}")
    reporte.append(f"   N√∫mero de clases: {len(clases)}")
    reporte.append("")
    
    # Exactitud
    reporte.append("2Ô∏è‚É£ EXACTITUD DEL MODELO")
    reporte.append("-" * 80)
    reporte.append(f"   Exactitud en datos de prueba: {accuracy*100:.2f}%")
    reporte.append("")
    
    if accuracy > 0.80:
        reporte.append("   ‚úÖ Excelente capacidad discriminante")
    elif accuracy > 0.70:
        reporte.append("   ‚úÖ Buena capacidad discriminante")
    elif accuracy > 0.60:
        reporte.append("   ‚ö†Ô∏è  Capacidad discriminante moderada")
    else:
        reporte.append("   ‚ö†Ô∏è  Baja capacidad discriminante")
    reporte.append("")
    
    # Matriz de confusi√≥n
    reporte.append("3Ô∏è‚É£ MATRIZ DE CONFUSI√ìN")
    reporte.append("-" * 80)
    reporte.append("   Ver gr√°fico: matriz_confusion_lda.png")
    reporte.append("")
    
    # An√°lisis por clase
    reporte.append("   M√©tricas por clase:")
    for i, clase in enumerate(clases):
        # Calcular precisi√≥n y recall para cada clase
        tp = cm[i, i]
        total_real = cm[i, :].sum()
        total_pred = cm[:, i].sum()
        
        recall = tp / total_real if total_real > 0 else 0
        precision = tp / total_pred if total_pred > 0 else 0
        
        reporte.append(f"      ‚Ä¢ {clase}:")
        reporte.append(f"        - Recall (sensibilidad): {recall*100:.1f}%")
        reporte.append(f"        - Precisi√≥n: {precision*100:.1f}%")
    reporte.append("")
    
    # Variables m√°s importantes
    reporte.append("4Ô∏è‚É£ VARIABLES M√ÅS IMPORTANTES PARA DISCRIMINACI√ìN")
    reporte.append("-" * 80)
    top_vars = df_coef.nlargest(10, 'Importancia')
    for var in top_vars.index:
        importancia = df_coef.loc[var, 'Importancia']
        reporte.append(f"   ‚Ä¢ {var}: {importancia:.4f}")
    reporte.append("")
    
    # Conclusi√≥n
    reporte.append("5Ô∏è‚É£ CONCLUSI√ìN")
    reporte.append("-" * 80)
    reporte.append("   El an√°lisis discriminante permite:")
    reporte.append(f"   ‚úì Clasificar observaciones en {len(clases)} grupos")
    reporte.append(f"   ‚úì Con una exactitud de {accuracy*100:.2f}%")
    reporte.append("   ‚úì Las variables listadas arriba son las m√°s discriminantes")
    reporte.append("")
    
    if len(clases) == 2:
        reporte.append("   üìå Con 2 clases, LDA crea 1 funci√≥n discriminante")
    else:
        reporte.append(f"   üìå Con {len(clases)} clases, LDA crea {len(clases)-1} funciones discriminantes")
    
    reporte.append("")
    reporte.append("=" * 80)
    
    # Guardar e imprimir
    reporte_text = "\n".join(reporte)
    print("\n" + reporte_text)
    
    path = Path(output_dir) / 'reporte_discriminante.txt'
    with open(path, 'w', encoding='utf-8') as f:
        f.write(reporte_text)
    
    print(f"\nüíæ Reporte guardado: {path}")

def main():
    """Funci√≥n principal"""
    print("=" * 80)
    print("üî¨ AN√ÅLISIS 2D: AN√ÅLISIS DISCRIMINANTE LINEAL (LDA)")
    print("=" * 80)
    
    # 1. Cargar datos
    df_valores, df_etiquetas = cargar_y_preparar_datos()
    
    # 2. Identificar variable categ√≥rica
    variable_obj, df_valores = identificar_variable_categorica(df_valores, df_etiquetas)
    
    # 3. Preparar datos
    X, y, clases = preparar_datos_discriminante(df_valores, variable_obj)
    
    # 4. Realizar an√°lisis discriminante
    lda, X_test, y_test, y_pred, clases, accuracy = realizar_analisis_discriminante(X, y, clases)
    
    # 5. Crear matriz de confusi√≥n
    cm = crear_matriz_confusion(y_test, y_pred, clases)
    
    # 6. Visualizar funciones discriminantes
    visualizar_discriminantes(lda, X_test, y_test, clases)
    
    # 7. Analizar coeficientes
    df_coef = analizar_coeficientes(lda, X.columns, clases)
    
    # 8. Generar reporte
    generar_reporte_discriminante(variable_obj, clases, accuracy, cm, df_coef)
    
    print("\n‚úÖ ¬°An√°lisis Discriminante completado!")
    
    return lda, accuracy, cm

if __name__ == "__main__":
    lda, accuracy, cm = main()
